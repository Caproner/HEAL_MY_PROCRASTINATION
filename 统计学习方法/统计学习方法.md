# 统计学习方法

+ [ ] 第1章：统计学习方法概论
+ [ ] 第2章：感知机
+ [ ] 第3章：k近邻法
+ [ ] 第4章：朴素贝叶斯法
+ [ ] 第5章：决策树
+ [ ] 第6章：逻辑斯蒂回归与最大熵模型
+ [ ] 第7章：支持向量机
+ [ ] 第8章：提升方法
+ [ ] 第9章：EM算法及其推广
+ [ ] 第10章：隐马尔可夫模型
+ [ ] 第11章：条件随机场
+ [ ] 第12章：统计学习方法总结

## 第1章：统计学习方法概论

+ 统计学习一般指统计机器学习。当前一般会使用统计学习方法模仿人工智能。
+ 本书着重介绍监督学习
+ 统计学习三要素：
  + 模型：学习到的用于解决问题的参数模型，可以是生成模型或判别模型
  + 策略：指模型的目标，一般会使用损失函数
  + 算法：指令模型到达目标的方法，可以是直接求解或者梯度下降
+ 统计学习策略的最小化目标包括两类：
  + 经验风险最小化：指最小化模型在训练数据上的误差
    + 我们期望学到对期望风险最小化的模型，但要得到期望风险我们就需要知道整个输入输出空间的联合概率分布。这显然不现实。所以我们退而求其次，使用搜集到的大量数据作为训练数据，并令模型在上面的风险最小化。该风险即为经验风险。
  + 结构风险最小化：等价于正则化
    + 如果没有最小化结构风险的话，模型很容易对数据过拟合。正则化则限制了模型的复杂程度，降低模型的结构风险。
+ 模型可以分为生成模型和判别模型：
  + 生成模型的目的是学习得到数据的联合概率分布<a href="https://www.codecogs.com/eqnedit.php?latex=P(X,Y)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(X,Y)" title="P(X,Y)" /></a>，而判别模型的目的是直接学习决策函数<a href="https://www.codecogs.com/eqnedit.php?latex=Y=f(X)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?Y=f(X)" title="Y=f(X)" /></a>或者条件概率分布<a href="https://www.codecogs.com/eqnedit.php?latex=P(Y|X)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?P(Y|X)" title="P(Y|X)" /></a>

